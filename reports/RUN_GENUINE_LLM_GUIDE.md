# How to Run Genuine LLM Venice Cascade Framework

## Quick Start

### 1. Setup API Key
Create `.env` file with your OpenAI API key:
```bash
echo "OPENAI_API_KEY=sk-your-actual-key-here" > .env
```

### 2. Install Dependencies
```bash
pip install openai python-dotenv loguru numpy
```

### 3. Run Framework
```bash
cd c:/dev/VeniceData
python scripts/genuine_llm_cascade_framework.py
```

## Expected Output

```
=== GENUINE LLM CASCADE DEMONSTRATION ===
LLM drives coordination decisions - NOT just content generation

--- Running GENUINE LLM COMMUNICATION BREAKDOWN ---
LLM makes actual coordination decisions (not just dialogue)

âœ… GENUINE LLM RESULTS:
   ğŸ“Š Total LLM decisions: 45
   ğŸ¯ Decision confidence: 0.73
   ğŸ¤ LLM coordination effectiveness: 0.67
   ğŸ“ˆ System degradation: 0.23
   ğŸ”„ Cascade events: 8
   ğŸ“ Decision types: {'commit': 28, 'reject': 15, 'negotiate': 2}

ğŸ§  SAMPLE LLM REASONING:
   1. "Given the critical flood stage and limited resources, San Marco can provide..."
   2. "The cultural heritage sector aligns well with emergency coordination needs..."

ğŸ‰ GENUINE LLM INTEGRATION COMPLETE!
ğŸ“ Files generated:
   - genuine_llm_decisions_communication_breakdown.json
   - genuine_llm_messages_communication_breakdown.ndjson
   - genuine_llm_snapshots_communication_breakdown.json
```

## Safety Features

The framework includes protections against infinite loops:

- **API Timeouts**: 30-second timeout on all LLM calls
- **Processing Limits**: Max 50 agents per tick, max 3 LLM decisions per agent
- **Error Recovery**: Individual agent errors don't crash simulation
- **API Monitoring**: Warns at 1000+ API calls and reduces activity
- **Progress Logging**: Tracks simulation advancement

## Files Generated

- **`genuine_llm_decisions_*.json`** - All LLM coordination decisions with reasoning
- **`genuine_llm_messages_*.ndjson`** - Complete message log with LLM content  
- **`genuine_llm_snapshots_*.json`** - System state evolution during simulation

## Research Integrity

âœ… **Zero Fallbacks** - LLM failures terminate rather than hide behind defaults  
âœ… **Zero Mock Data** - Only genuine agent states drive coordination  
âœ… **Zero Hardcoded Values** - All responses require complete LLM parsing  
âœ… **Pure LLM Behavior** - Every decision comes from actual LLM reasoning  

## Troubleshooting

**"OPENAI_API_KEY required"**
- Check `.env` file exists with valid API key

**"LLM coordination decision required but failed"**  
- Check internet connection and API credits
- Framework will terminate rather than use fallback behavior

**"No module named 'fixed_cascade_scenarios'"**
- Run from correct directory: `c:/dev/VeniceData`

**High API usage warnings**
- Normal for genuine LLM integration (50-150 calls per scenario)
- Cost estimate: $0.10-0.50 per scenario with GPT-4

This framework ensures 100% genuine research with LLM-driven coordination decisions.